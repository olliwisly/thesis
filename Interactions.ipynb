{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions='https://bnf.nice.org.uk/interaction/'\n",
    "os.chdir('C:\\\\Users\\\\Oliver\\\\Desktop\\\\uni\\\\DataSc u MachLearn MSc\\\\project\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(interactions) as response:\n",
    "        webcont=response.read()\n",
    "soup=BeautifulSoup(webcont)\n",
    "data=soup.findAll(href=True)\n",
    "alllinks=list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "linklist=[]\n",
    "for i in range(35,len(data)):\n",
    "    endlink=str(data[i]).find('html')\n",
    "    endlink+=4\n",
    "    if str(data[i])[9]!='a':\n",
    "        break\n",
    "    linklist.append(str(data[i])[9:endlink])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingb=0\n",
    "\n",
    "if ingb==1:\n",
    "    alldata=[]\n",
    "    for i in range(len(linklist)):\n",
    "        alldata.append(linklist[i][:-7])\n",
    "        if alldata[-1][0]!='a':\n",
    "            break\n",
    "        with urllib.request.urlopen(interactions+linklist[i]) as response:\n",
    "            currwebcont=response.read()\n",
    "        currsoup=BeautifulSoup(currwebcont)\n",
    "        finddivint=currsoup.findAll(\"div\",\"interactions\")\n",
    "        alldata.append(finddivint)\n",
    "        currint=[]\n",
    "        for i in finddivint:\n",
    "            currint.append(str(i))\n",
    "\n",
    "        interactants={} #add name, color, text\n",
    "\n",
    "        stop=0\n",
    "        currpos=0\n",
    "        tofind='<h5 class=\"interactant\"><span>'\n",
    "        tofind2='<div class=\"interaction-message'\n",
    "        while stop==0:\n",
    "            #Name:\n",
    "            currpos0=currint[0][currpos:].find(tofind)\n",
    "            if currpos0==-1:\n",
    "                stop=1\n",
    "                continue\n",
    "            else:\n",
    "                currpos0+=len(tofind)\n",
    "            currpos1=currint[0][currpos+currpos0:].find('<')\n",
    "            name=currint[0][currpos+currpos0:currpos+currpos0+currpos1]\n",
    "            currpos+=currpos0+currpos1\n",
    "\n",
    "            #Text:\n",
    "            currposnext=currint[0][currpos:].find(tofind)\n",
    "            if currposnext==-1:\n",
    "                currposnext=len(currint[0])+1\n",
    "            cleaner=re.compile('<.*?>')\n",
    "\n",
    "            cleantext=\"\"\n",
    "            cleantext=re.sub(cleaner,'',currint[0][currpos:currpos+currposnext])\n",
    "            cleantext=cleantext.replace('\\r',' ').replace('\\n',' ')\n",
    "            cleantext=' '.join(cleantext.split())\n",
    "\n",
    "\n",
    "            #Severity/color:\n",
    "            currseverity=\"\"\n",
    "            currpos0=currint[0][currpos:].find(tofind2)\n",
    "            if currpos0!=-1:\n",
    "                currpos1=currint[0][currpos+currpos0+len(tofind2):].find('\"')\n",
    "                currseverity=currint[0][currpos+currpos0+len(tofind2):currpos+currpos0+len(tofind2)+currpos1]\n",
    "            interactants[name]=[currseverity.strip(),cleantext]\n",
    "        alldata.append(interactants)\n",
    "    with open(\"interactants.csv\",'w', newline='',encoding=\"utf-8\") as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(alldata)\n",
    "else:\n",
    "    interactions=[]\n",
    "    with open('interactants.csv', 'r',newline='',encoding=\"utf-8\") as csvfile:   # Unpickling\n",
    "        csvreader = csv.reader(csvfile,quoting=csv.QUOTE_ALL)\n",
    "        for row in csvreader:\n",
    "            interactions.append(row)\n",
    "    if len(interactions)==1:\n",
    "        interactions=interactions[0]\n",
    "    \n",
    "    for i in range(0,len(interactions),3):\n",
    "        alldata.append(interactions[i])\n",
    "        alldata.append(interactions[i+2])\n",
    "        \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"interactions.csv\",'w',newline='', encoding=\"utf-8\") as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
